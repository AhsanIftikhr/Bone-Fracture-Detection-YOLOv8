{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SZULmPuevZC",
        "outputId": "8eee2e68-f4e1-48e6-c453-159b4faa628a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Root Set To: /content/drive/MyDrive/YOLO_Data/archive/bone fracture detection.v4-v4.yolov8\n"
          ]
        }
      ],
      "source": [
        "# Mounting Google Drive and Setting Dataset Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "dataset_root = r'/content/drive/MyDrive/YOLO_Data/archive'\n",
        "SUBFOLDER_NAME = 'bone fracture detection.v4-v4.yolov8'\n",
        "\n",
        "FULL_DATASET_PATH = os.path.join(dataset_root, SUBFOLDER_NAME)\n",
        "print(f\"Dataset Root Set To: {FULL_DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training YOLOv8 Model on Bone Fracture Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKBhI-YFsi4t",
        "outputId": "bf96c692-4c0d-4207-ee39-704b238f634e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Root Set To: /content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8\n",
            "\n",
            "Configuration file found. Starting training for 20 epochs...\n",
            "Ultralytics 8.3.231 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fracture_detection_colab_20e, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_Results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.9¬±0.5 ms, read: 4.4¬±4.0 MB/s, size: 12.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8/train/labels.cache... 3631 images, 1827 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3631/3631 4.9Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 1.0¬±0.5 ms, read: 2.1¬±2.3 MB/s, size: 9.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8/valid/labels.cache... 348 images, 175 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 348/348 82.0Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.64G      2.773       6.73      2.313         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.1it/s 1:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.4it/s 4.5s\n",
            "                   all        348        204      0.858    0.00775    0.00791    0.00299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      2.64G      2.523      5.147      2.086         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.7it/s 3.0s\n",
            "                   all        348        204      0.548     0.0394     0.0251    0.00846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      2.64G      2.448      4.236      2.055         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.3it/s 3.4s\n",
            "                   all        348        204      0.479     0.0292     0.0202    0.00903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      2.65G      2.444      3.806      2.026         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 4.3it/s 2.6s\n",
            "                   all        348        204      0.377     0.0782     0.0757     0.0208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      2.67G      2.347      3.544      1.974         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.4it/s 4.6s\n",
            "                   all        348        204     0.0973      0.119     0.0779      0.029\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      2.69G      2.246      3.223      1.935         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.2it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 4.2it/s 2.6s\n",
            "                   all        348        204      0.189      0.213      0.098     0.0346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20       2.7G      2.228      3.093      1.902         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.2it/s 1:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.7it/s 2.9s\n",
            "                   all        348        204      0.356      0.168      0.152     0.0544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20       2.7G      2.183       2.93      1.891         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.5it/s 3.2s\n",
            "                   all        348        204      0.362      0.181      0.167      0.063\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20       2.7G      2.123       2.81      1.866         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.3it/s 1:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.2it/s 3.4s\n",
            "                   all        348        204      0.288      0.222      0.194     0.0699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20       2.7G      2.086      2.708      1.824         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.2it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.7it/s 3.0s\n",
            "                   all        348        204      0.217      0.207      0.191      0.067\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20       2.7G      2.046      2.587      1.923          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 2.9it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.9it/s 2.8s\n",
            "                   all        348        204      0.328      0.269      0.216     0.0784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20       2.7G      1.998      2.461      1.889         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.6it/s 3.0s\n",
            "                   all        348        204      0.252      0.254      0.188     0.0719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20       2.7G      1.971      2.341       1.89          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.4it/s 1:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.2it/s 3.4s\n",
            "                   all        348        204       0.18      0.273      0.201     0.0759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20       2.7G      1.904      2.239      1.848          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.6it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.7it/s 3.0s\n",
            "                   all        348        204      0.275      0.293      0.209     0.0773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20       2.7G      1.863      2.144      1.822         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.4it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.7it/s 2.9s\n",
            "                   all        348        204      0.294      0.268      0.232     0.0909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20       2.7G      1.811      1.987      1.768         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.4it/s 1:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.0it/s 3.6s\n",
            "                   all        348        204      0.311      0.266      0.234     0.0896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20       2.7G      1.781      1.889      1.747         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.9it/s 3.8s\n",
            "                   all        348        204      0.333      0.263      0.248     0.0938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20       2.7G       1.69      1.783      1.676         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.7it/s 4.0s\n",
            "                   all        348        204      0.315      0.306      0.244     0.0883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20       2.7G      1.689      1.727      1.674          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.6it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.9it/s 3.8s\n",
            "                   all        348        204        0.4      0.257       0.26     0.0933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20       2.7G      1.627      1.632      1.611         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227/227 3.6it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 4.3it/s 2.5s\n",
            "                   all        348        204      0.338      0.306      0.263     0.0934\n",
            "\n",
            "20 epochs completed in 0.405 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/weights/best.pt...\n",
            "Ultralytics 8.3.231 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 2.4it/s 4.6s\n",
            "                   all        348        204      0.332      0.261      0.247      0.093\n",
            "        elbow positive         28         29     0.0906      0.069     0.0797     0.0472\n",
            "      fingers positive         41         48      0.213     0.0833     0.0865     0.0244\n",
            "      forearm fracture         37         43      0.621       0.42      0.494      0.204\n",
            "               humerus         31         36      0.648      0.563      0.557        0.2\n",
            "     shoulder fracture         19         20      0.232       0.25      0.187     0.0665\n",
            "        wrist positive         17         28      0.185      0.179     0.0782     0.0163\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e\u001b[0m\n",
            "\n",
            "Training Complete! Check the 'YOLO_Results' folder in your Drive for weights and metrics.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "dataset_root = r'/content/drive/MyDrive/archive'\n",
        "SUBFOLDER_NAME = 'bone fracture detection.v4-v4.yolov8'\n",
        "FULL_DATASET_PATH = os.path.join(dataset_root, SUBFOLDER_NAME)\n",
        "\n",
        "print(f\"Dataset Root Set To: {FULL_DATASET_PATH}\")\n",
        "\n",
        "def train_model():\n",
        "\n",
        "\n",
        "    yaml_path = os.path.join(FULL_DATASET_PATH, \"data.yaml\")\n",
        "\n",
        "    if not os.path.exists(yaml_path):\n",
        "        print(f\"\\nERROR: Configuration file not found at {yaml_path}.\")\n",
        "        print(\"Please verify the full path of the 'archive' folder in your Drive.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\nConfiguration file found. Starting training for 20 epochs...\")\n",
        "\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=20,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        name='fracture_detection_colab_20e',\n",
        "        project='/content/drive/MyDrive/YOLO_Results',\n",
        "        device=0\n",
        "    )\n",
        "\n",
        "    print(\"\\nTraining Complete! Check the 'YOLO_Results' folder in your Drive for weights and metrics.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing and Validating the Trained YOLOv8 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIrdsEIXvqdY",
        "outputId": "9fa617c2-b77a-4c31-da01-50a8e95e7854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Dataset Root Set To: /content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8\n",
            "\n",
            "‚úÖ Loading trained model from: /content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/weights/best.pt\n",
            "\n",
            "--- Starting Inference (Prediction) ---\n",
            "Running inference on 169 test images...\n",
            "\n",
            "0: 640x640 (no detections), 3.3ms\n",
            "1: 640x640 (no detections), 3.3ms\n",
            "2: 640x640 (no detections), 3.3ms\n",
            "3: 640x640 (no detections), 3.3ms\n",
            "4: 640x640 (no detections), 3.3ms\n",
            "5: 640x640 (no detections), 3.3ms\n",
            "6: 640x640 1 forearm fracture, 3.3ms\n",
            "7: 640x640 (no detections), 3.3ms\n",
            "8: 640x640 (no detections), 3.3ms\n",
            "9: 640x640 (no detections), 3.3ms\n",
            "10: 640x640 (no detections), 3.3ms\n",
            "11: 640x640 (no detections), 3.3ms\n",
            "12: 640x640 (no detections), 3.3ms\n",
            "13: 640x640 1 shoulder fracture, 3.3ms\n",
            "14: 640x640 (no detections), 3.3ms\n",
            "15: 640x640 (no detections), 3.3ms\n",
            "16: 640x640 (no detections), 3.3ms\n",
            "17: 640x640 (no detections), 3.3ms\n",
            "18: 640x640 (no detections), 3.3ms\n",
            "19: 640x640 1 shoulder fracture, 3.3ms\n",
            "20: 640x640 (no detections), 3.3ms\n",
            "21: 640x640 (no detections), 3.3ms\n",
            "22: 640x640 (no detections), 3.3ms\n",
            "23: 640x640 (no detections), 3.3ms\n",
            "24: 640x640 (no detections), 3.3ms\n",
            "25: 640x640 1 elbow positive, 3.3ms\n",
            "26: 640x640 (no detections), 3.3ms\n",
            "27: 640x640 1 elbow positive, 3.3ms\n",
            "28: 640x640 (no detections), 3.3ms\n",
            "29: 640x640 3 humeruss, 3.3ms\n",
            "30: 640x640 (no detections), 3.3ms\n",
            "31: 640x640 (no detections), 3.3ms\n",
            "32: 640x640 (no detections), 3.3ms\n",
            "33: 640x640 2 humeruss, 3.3ms\n",
            "34: 640x640 (no detections), 3.3ms\n",
            "35: 640x640 (no detections), 3.3ms\n",
            "36: 640x640 (no detections), 3.3ms\n",
            "37: 640x640 1 humerus, 3.3ms\n",
            "38: 640x640 (no detections), 3.3ms\n",
            "39: 640x640 (no detections), 3.3ms\n",
            "40: 640x640 (no detections), 3.3ms\n",
            "41: 640x640 (no detections), 3.3ms\n",
            "42: 640x640 (no detections), 3.3ms\n",
            "43: 640x640 1 forearm fracture, 3.3ms\n",
            "44: 640x640 (no detections), 3.3ms\n",
            "45: 640x640 (no detections), 3.3ms\n",
            "46: 640x640 (no detections), 3.3ms\n",
            "47: 640x640 2 fingers positives, 3.3ms\n",
            "48: 640x640 (no detections), 3.3ms\n",
            "49: 640x640 (no detections), 3.3ms\n",
            "50: 640x640 2 wrist positives, 3.3ms\n",
            "51: 640x640 (no detections), 3.3ms\n",
            "52: 640x640 2 shoulder fractures, 3.3ms\n",
            "53: 640x640 (no detections), 3.3ms\n",
            "54: 640x640 (no detections), 3.3ms\n",
            "55: 640x640 (no detections), 3.3ms\n",
            "56: 640x640 (no detections), 3.3ms\n",
            "57: 640x640 (no detections), 3.3ms\n",
            "58: 640x640 (no detections), 3.3ms\n",
            "59: 640x640 (no detections), 3.3ms\n",
            "60: 640x640 (no detections), 3.3ms\n",
            "61: 640x640 (no detections), 3.3ms\n",
            "62: 640x640 (no detections), 3.3ms\n",
            "63: 640x640 (no detections), 3.3ms\n",
            "64: 640x640 (no detections), 3.3ms\n",
            "65: 640x640 (no detections), 3.3ms\n",
            "66: 640x640 (no detections), 3.3ms\n",
            "67: 640x640 (no detections), 3.3ms\n",
            "68: 640x640 (no detections), 3.3ms\n",
            "69: 640x640 (no detections), 3.3ms\n",
            "70: 640x640 (no detections), 3.3ms\n",
            "71: 640x640 (no detections), 3.3ms\n",
            "72: 640x640 (no detections), 3.3ms\n",
            "73: 640x640 1 wrist positive, 3.3ms\n",
            "74: 640x640 (no detections), 3.3ms\n",
            "75: 640x640 (no detections), 3.3ms\n",
            "76: 640x640 (no detections), 3.3ms\n",
            "77: 640x640 1 forearm fracture, 3.3ms\n",
            "78: 640x640 (no detections), 3.3ms\n",
            "79: 640x640 (no detections), 3.3ms\n",
            "80: 640x640 (no detections), 3.3ms\n",
            "81: 640x640 (no detections), 3.3ms\n",
            "82: 640x640 (no detections), 3.3ms\n",
            "83: 640x640 (no detections), 3.3ms\n",
            "84: 640x640 (no detections), 3.3ms\n",
            "85: 640x640 (no detections), 3.3ms\n",
            "86: 640x640 (no detections), 3.3ms\n",
            "87: 640x640 (no detections), 3.3ms\n",
            "88: 640x640 (no detections), 3.3ms\n",
            "89: 640x640 (no detections), 3.3ms\n",
            "90: 640x640 (no detections), 3.3ms\n",
            "91: 640x640 (no detections), 3.3ms\n",
            "92: 640x640 (no detections), 3.3ms\n",
            "93: 640x640 (no detections), 3.3ms\n",
            "94: 640x640 (no detections), 3.3ms\n",
            "95: 640x640 (no detections), 3.3ms\n",
            "96: 640x640 (no detections), 3.3ms\n",
            "97: 640x640 (no detections), 3.3ms\n",
            "98: 640x640 (no detections), 3.3ms\n",
            "99: 640x640 1 humerus, 3.3ms\n",
            "100: 640x640 (no detections), 3.3ms\n",
            "101: 640x640 (no detections), 3.3ms\n",
            "102: 640x640 1 humerus, 3.3ms\n",
            "103: 640x640 (no detections), 3.3ms\n",
            "104: 640x640 (no detections), 3.3ms\n",
            "105: 640x640 (no detections), 3.3ms\n",
            "106: 640x640 (no detections), 3.3ms\n",
            "107: 640x640 (no detections), 3.3ms\n",
            "108: 640x640 (no detections), 3.3ms\n",
            "109: 640x640 (no detections), 3.3ms\n",
            "110: 640x640 (no detections), 3.3ms\n",
            "111: 640x640 (no detections), 3.3ms\n",
            "112: 640x640 1 wrist positive, 3.3ms\n",
            "113: 640x640 (no detections), 3.3ms\n",
            "114: 640x640 (no detections), 3.3ms\n",
            "115: 640x640 (no detections), 3.3ms\n",
            "116: 640x640 (no detections), 3.3ms\n",
            "117: 640x640 (no detections), 3.3ms\n",
            "118: 640x640 (no detections), 3.3ms\n",
            "119: 640x640 (no detections), 3.3ms\n",
            "120: 640x640 (no detections), 3.3ms\n",
            "121: 640x640 (no detections), 3.3ms\n",
            "122: 640x640 (no detections), 3.3ms\n",
            "123: 640x640 (no detections), 3.3ms\n",
            "124: 640x640 (no detections), 3.3ms\n",
            "125: 640x640 1 fingers positive, 1 wrist positive, 3.3ms\n",
            "126: 640x640 (no detections), 3.3ms\n",
            "127: 640x640 (no detections), 3.3ms\n",
            "128: 640x640 (no detections), 3.3ms\n",
            "129: 640x640 1 forearm fracture, 3.3ms\n",
            "130: 640x640 1 shoulder fracture, 3.3ms\n",
            "131: 640x640 (no detections), 3.3ms\n",
            "132: 640x640 (no detections), 3.3ms\n",
            "133: 640x640 (no detections), 3.3ms\n",
            "134: 640x640 2 fingers positives, 3.3ms\n",
            "135: 640x640 (no detections), 3.3ms\n",
            "136: 640x640 (no detections), 3.3ms\n",
            "137: 640x640 1 forearm fracture, 3.3ms\n",
            "138: 640x640 1 shoulder fracture, 3.3ms\n",
            "139: 640x640 1 forearm fracture, 3.3ms\n",
            "140: 640x640 (no detections), 3.3ms\n",
            "141: 640x640 1 shoulder fracture, 3.3ms\n",
            "142: 640x640 (no detections), 3.3ms\n",
            "143: 640x640 (no detections), 3.3ms\n",
            "144: 640x640 (no detections), 3.3ms\n",
            "145: 640x640 (no detections), 3.3ms\n",
            "146: 640x640 1 fingers positive, 3.3ms\n",
            "147: 640x640 (no detections), 3.3ms\n",
            "148: 640x640 (no detections), 3.3ms\n",
            "149: 640x640 (no detections), 3.3ms\n",
            "150: 640x640 (no detections), 3.3ms\n",
            "151: 640x640 (no detections), 3.3ms\n",
            "152: 640x640 (no detections), 3.3ms\n",
            "153: 640x640 (no detections), 3.3ms\n",
            "154: 640x640 (no detections), 3.3ms\n",
            "155: 640x640 (no detections), 3.3ms\n",
            "156: 640x640 (no detections), 3.3ms\n",
            "157: 640x640 (no detections), 3.3ms\n",
            "158: 640x640 1 wrist positive, 3.3ms\n",
            "159: 640x640 (no detections), 3.3ms\n",
            "160: 640x640 (no detections), 3.3ms\n",
            "161: 640x640 (no detections), 3.3ms\n",
            "162: 640x640 (no detections), 3.3ms\n",
            "163: 640x640 (no detections), 3.3ms\n",
            "164: 640x640 (no detections), 3.3ms\n",
            "165: 640x640 (no detections), 3.3ms\n",
            "166: 640x640 (no detections), 3.3ms\n",
            "167: 640x640 (no detections), 3.3ms\n",
            "168: 640x640 (no detections), 3.3ms\n",
            "Speed: 11.0ms preprocess, 3.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/YOLO_Test_Results/inference_on_test_set4\u001b[0m\n",
            "\n",
            "Prediction Complete!\n",
            "üñºÔ∏è Check your Google Drive for predicted images with bounding boxes:\n",
            "/content/drive/MyDrive/YOLO_Test_Results/inference_on_test_set\n",
            "\n",
            "--- Starting Validation (Quantitative Metrics) ---\n",
            "Ultralytics 8.3.231 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.6¬±0.3 ms, read: 6.3¬±3.5 MB/s, size: 12.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/archive/bone fracture detection.v4-v4.yolov8/valid/labels.cache... 348 images, 175 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 348/348 623.2Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 5.3it/s 4.1s\n",
            "                   all        348        204      0.309      0.266      0.245     0.0943\n",
            "        elbow positive         28         29     0.0799      0.069     0.0819     0.0483\n",
            "      fingers positive         41         48      0.228      0.104     0.0867     0.0235\n",
            "      forearm fracture         37         43      0.545      0.419      0.492      0.217\n",
            "               humerus         31         36      0.613      0.573      0.556      0.198\n",
            "     shoulder fracture         19         20      0.225       0.25      0.175     0.0633\n",
            "        wrist positive         17         28      0.165      0.179     0.0781     0.0165\n",
            "Speed: 1.9ms preprocess, 3.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "--- Validation Metrics Summary ---\n",
            "Metrics saved to: /content/runs/detect/val2\n",
            "  - mAP50 (Mean Average Precision at IoU 0.5): 0.2451\n",
            "  - mAP50-95 (mAP across IoU 0.5 to 0.95): 0.0943\n",
            "  - Loss/Metrics plots, Confusion Matrix, and other results saved to this directory.\n",
            "\n",
            "Testing and Validation workflow finished.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "dataset_root = r'/content/drive/MyDrive/archive'\n",
        "SUBFOLDER_NAME = 'bone fracture detection.v4-v4.yolov8'\n",
        "\n",
        "\n",
        "FULL_DATASET_PATH = os.path.join(dataset_root, SUBFOLDER_NAME)\n",
        "SAVED_MODEL_PATH = '/content/drive/MyDrive/YOLO_Results/fracture_detection_colab_20e/weights/best.pt'\n",
        "\n",
        "TEST_IMAGES_DIR = os.path.join(FULL_DATASET_PATH, 'test', 'images')\n",
        "YAML_PATH = os.path.join(FULL_DATASET_PATH, \"data.yaml\")\n",
        "\n",
        "print(f\"Dataset Root Set To: {FULL_DATASET_PATH}\")\n",
        "\n",
        "def test_model():\n",
        "    if not os.path.exists(SAVED_MODEL_PATH):\n",
        "        print(f\"\\nERROR: Trained model weights not found at: {SAVED_MODEL_PATH}\")\n",
        "        print(\"Please check the 'YOLO_Results' folder in your Drive to confirm the path.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nLoading trained model from: {SAVED_MODEL_PATH}\")\n",
        "    model = YOLO(SAVED_MODEL_PATH)\n",
        "    print(\"\\n--- Starting Inference (Prediction) ---\")\n",
        "    test_files = glob.glob(os.path.join(TEST_IMAGES_DIR, '*.jpg'))\n",
        "\n",
        "    if not test_files:\n",
        "        print(f\"WARNING: No JPG images found in the test directory: {TEST_IMAGES_DIR}\")\n",
        "        print(\"Skipping inference, proceeding to validation...\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Running inference on {len(test_files)} test images...\")\n",
        "        results = model.predict(\n",
        "            source=test_files,\n",
        "            conf=0.25,\n",
        "            save=True,\n",
        "            project='/content/drive/MyDrive/YOLO_Test_Results',\n",
        "            name='inference_on_test_set',\n",
        "            imgsz=640,\n",
        "            device=0\n",
        "        )\n",
        "\n",
        "        print(\"\\nPrediction Complete!\")\n",
        "        print(\"Check your Google Drive for predicted images with bounding boxes:\")\n",
        "        print(\"/content/drive/MyDrive/YOLO_Test_Results/inference_on_test_set\")\n",
        "\n",
        "    print(\"\\n--- Starting Validation (Quantitative Metrics) ---\")\n",
        "    if not os.path.exists(YAML_PATH):\n",
        "        print(f\"ERROR: data.yaml not found at {YAML_PATH}. Cannot run validation.\")\n",
        "        return\n",
        "\n",
        "    metrics = model.val(data=YAML_PATH)\n",
        "    print(\"\\n--- Validation Metrics Summary ---\")\n",
        "    print(f\"Metrics saved to: {metrics.save_dir}\")\n",
        "    print(f\"  - mAP50 (Mean Average Precision at IoU 0.5): {metrics.box.map50:.4f}\")\n",
        "    print(f\"  - mAP50-95 (mAP across IoU 0.5 to 0.95): {metrics.box.map:.4f}\")\n",
        "    print(\"  - Loss/Metrics plots, Confusion Matrix, and other results saved to this directory.\")\n",
        "\n",
        "    print(\"\\nTesting and Validation workflow finished.\")\n",
        "\n",
        "if __name__ == '__main__': test_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
